
\chapwithtoc{Conclusion}

In this thesis reinforcement learning was formally introduced along with several methods such as Q-learning or REINFORCE. Then evolutionary algorithms were described and further expanded by evolutionary strategies including the introduction of CMA-ES. Following that OpenAI-ES, a evolutionary strategy that was designed for solving reinforcement learning tasks, high level of paralellisation and doesn't require differentiable policy as there is no differentiation needed unlike in traditional methods such as REINFORCE. This algorithm is further extended with novelty search which uses behavioral characteristics of evolved agents to evolve agents to behave in a different manner than their ancestors which should enable the agents to deal with falling into a local optima. Then test 2 test environment were introduced and data from experiments discussed. Finally some technical details about the implementation were explained.

\xxx{Based on conducted experiments...}



